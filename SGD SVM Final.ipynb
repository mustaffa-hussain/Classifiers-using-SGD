{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2S-uFqwSvmg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUxLkBjISvmr"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xexp5GYNSvmz",
    "outputId": "48e3356f-3756-4945-f6b7-f643b59063b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9pKAn1-ASvm_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r97pFTgrSvnE"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jykLIXZNSvnJ",
    "outputId": "2e462e5f-1546-4edf-bcc8-e7a42f9057d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0-M6oXASvnO"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sShoMeocSvnP"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gm6wi8L2SvnU",
    "outputId": "dccc42b5-e1eb-4e2f-9fa2-07f405d4f761"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q4WFoxgASvnc",
    "outputId": "469de818-0a3e-42e8-bc19-ac6d088b9617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.18 seconds.\n",
      "Convergence after 10 epochs took 0.18 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WaVxhGpSvnj",
    "outputId": "1e67badc-96e7-4633-eb72-1d4c24aaa295"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Su9e8fRLSvno"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gcz5_UqCSvnq"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOBvEchCSvnr"
   },
   "source": [
    "## Implement Logistc Regression with L2 regularization Using SGD: without using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xbn61rrXSvnt"
   },
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "14bA5yR3Svnv"
   },
   "source": [
    "- Load the datasets(train and test) into the respective arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7183hFBSvnv"
   },
   "source": [
    "- Initialize the weight_vector and intercept term randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdLeFU0USvnx"
   },
   "source": [
    "- Calculate the initlal log loss for the train and test data with the current weight and intercept and store it in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pEVtAlO1Svny"
   },
   "source": [
    "- for each epoch:\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector\n",
    "        - Calculate the gradient of the intercept <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)} ← (1 − \\frac{αλ}{N} )w^{(t)} + αx_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))$ <br>\n",
    "        $b^{(t+1)} ← (b^t +  α(y_n - σ((w^{(t)})^{T} x_n+b^{t}))$ \n",
    "        - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "        - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "        - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2qmRH4UpSvny"
   },
   "source": [
    "- Plot the train and test loss i.e on x-axis the epoch number, and on y-axis the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbZf9p5gSvn1"
   },
   "source": [
    "- <strong>GOAL</strong>: compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48gx6wQKSvoE",
    "outputId": "73838465-1f8e-4697-fe22-c49a816e1207"
   },
   "outputs": [],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        if sigmoid(w, X[i], b) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "\n",
    "def sigmoid(w,x,b):\n",
    "    gamma=np.dot(w,x)+b\n",
    "    if gamma < 0:\n",
    "        return 1 - 1 / (1 + math.exp(gamma))\n",
    "    return 1 / (1 + math.exp(-gamma))\n",
    "\n",
    "def sig_pred(w,X,b):\n",
    "    a=[]\n",
    "    for x in X:\n",
    "        a.append(sigmoid(w,x,b))\n",
    "#         a.append(1/(1+math.exp(-(np.dot(x,w)+b))))\n",
    "    return a\n",
    "    \n",
    "    \n",
    "from math import log\n",
    "def compute_log_loss(A,B):\n",
    "    n = len(A)\n",
    "    res = 0\n",
    "    for l in zip(A,B):\n",
    "        res += l[0] * log(l[1]) + (1 - l[0]) * log(1 - l[1])                   \n",
    "    loss = (-1 * res) / n\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fpz8X5DMSvn2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the initial train loss is : 0.6931471805594285  at W: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]   and b : 0\n",
      "the initial test loss is : 0.6931471805600672  at W: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]   and b : 0\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros_like(X_train[0])\n",
    "b = 0\n",
    "eta0  = 0.0001\n",
    "alpha = 0.0001\n",
    "N = len(X_train)\n",
    "print(\"the initial train loss is :\" ,compute_log_loss(y_train,sig_pred(w,X_train,b)),\" at W:\",w,\"  and b :\",b)\n",
    "\n",
    "print(\"the initial test loss is :\" ,compute_log_loss(y_test,sig_pred(w,X_test,b)),\" at W:\",w,\"  and b :\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6Y5kVscSvn5"
   },
   "outputs": [],
   "source": [
    "# write your code to implement SGD as per the above instructions\n",
    "# please choose the number of iternations on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(X_train,X_test,y_train,y_test,n,w,b):\n",
    "    del_w=np.zeros_like(X_train[0])\n",
    "    del_b=0\n",
    "    wl=[]\n",
    "    bl=[]\n",
    "    log_loss_train=[]\n",
    "    log_loss_test=[]\n",
    "    for epoch in range(n):\n",
    "        for m in range(len(X_train)):\n",
    "            del_w=alpha*X_train[m]*(y_train[m]-sigmoid(w,X_train[m],b))\n",
    "            del_b=alpha*(y_train[m]-sigmoid(w,X_train[m],b))\n",
    "            w=(1-(eta0*alpha/n))*w+del_w\n",
    "#             w=(1-(alpha/n))*w+del_w\n",
    "            b=b+del_b\n",
    "        wl.append(w)\n",
    "        bl.append(b)\n",
    "        log_loss_train.append(compute_log_loss(y_train,sig_pred(w,X_train,b)))\n",
    "        log_loss_test.append(compute_log_loss(y_test,sig_pred(w,X_test,b)))       \n",
    "        \n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(log_loss_train, label='train_log_loss')\n",
    "    plt.plot(log_loss_test, label='test_log_loss')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.title('Log loss vs epoch')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('log loss')\n",
    "    plt.show()\n",
    "        \n",
    "    return log_loss_train,log_loss_test,wl,bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logloss_train,logloss_test,W,B=sgd(X_train,X_test,y_train,y_test,300,w,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can see that the least training error is at:  107  and the least test error is at:  89  iterations.\n",
      "\n",
      "The logg loss for test data is :  0.38021534747564634\n",
      "\n",
      "The decision vector is : [-0.42979168  0.19303488 -0.14846942  0.33809295 -0.22128174  0.56994779\n",
      " -0.44518105 -0.08990385  0.22182917  0.17382915  0.19874809 -0.00058436\n",
      " -0.08133393  0.33908952  0.02298802]\n",
      "\n",
      "The bias is : -0.8922521895400071\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ind = np.argmin(logloss_train)\n",
    "ind_t=np.argmin(logloss_test)\n",
    "print(\"We can see that the least training error is at: \",ind,\" and the least test error is at: \",ind_t,\" iterations.\")\n",
    "print(\"\\nThe logg loss for test data is : \",logloss_test[ind])\n",
    "print(\"\\nThe decision vector is :\",W[ind])\n",
    "print(\"\\nThe bias is :\",B[ind])\n",
    "# print(\"\\nThe test accuracy is : \", accuracy_score(y_test,pred(W[ind],B[ind],X_test)))\n",
    "# print(\"\\nThe train accuracy is : \", accuracy_score(y_train,pred(W[ind],B[ind],X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the difference between the custom learnt vectors and the sklearn vectors is :\n",
      " \n",
      "[[0.00642476 0.00755923 0.00012094 0.00335112 0.01309504 0.00978201\n",
      "  0.00724378 0.00418428 0.01255597 0.00701211 0.00169618 0.00480352\n",
      "  0.00173024 0.00056151 0.00032081]]\n",
      "--------------------------------------------------\n",
      "\n",
      "the difference between the custom learnt bias and the sklearn bias is : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.03911389])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"the difference between the custom learnt vectors and the sklearn vectors is :\\n \")\n",
    "print(abs(clf.coef_-W[ind]))\n",
    "print(\"--\"*25)\n",
    "print(\"\\nthe difference between the custom learnt bias and the sklearn bias is : \")\n",
    "abs(clf.intercept_-B[ind])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Logistic Regression using SGD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
