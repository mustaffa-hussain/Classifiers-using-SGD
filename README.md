![SGD](sgd image.png?style=centerme)



# Logistic-regression-using-SGD
This repository has the implementation of Logistic Regression using the method of Stochastic Gradient Descent.

<br>Stochastic gradient descent (often abbreviated SGD) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data).

